{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP pipeline\n",
    "1. load input file and read reviews\n",
    "2. tokenize\n",
    "3. remove stopwards\n",
    "4. perform stemming\n",
    "5. write cleamned data to output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"\"I loved this movie since I was 7 and I saw it on the opening day. It was so touching and beautiful. I strongly recommend seeing for all. It's a movie to watch with your family by far.<br /><br />My MPAA rating: PG-13 for thematic elements, prolonged scenes of disastor, nudity/sexuality and some language.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "ps = PorterStemmer()\n",
    "en_stopwords = set(stopwords.words('english'))\n",
    "if 'not' in en_stopwords:\n",
    "    en_stopwords.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'why', 'myself', 'my', 'if', 'and', 'our', 'there', 'that', 'before', 'above', 'here', \"she's\", \"you're\", \"doesn't\", \"shan't\", \"weren't\", 'each', 'the', 'has', \"hasn't\", 'any', 'just', 'wouldn', 'o', 'who', 'can', 'mustn', 'at', 'through', 'from', \"couldn't\", 'same', 'a', 'few', 'haven', 'by', 'these', 'but', 'm', 'too', 'y', 'once', 'about', \"should've\", 'own', 'had', 'this', 'over', 'all', 'to', \"don't\", 'up', 'so', \"that'll\", 'am', 'again', 'off', 'needn', 'very', 'i', 'yourself', 'her', 'herself', 'more', 'doing', 'into', 'have', \"shouldn't\", 'wasn', 'were', 'then', \"haven't\", 's', 'because', 'such', 'weren', 'been', 'themselves', 'down', 'being', 'when', 'hers', 'other', 'shouldn', 'ain', 'an', 'hasn', 'itself', 'during', 'which', 'their', 'them', 'hadn', 'will', \"won't\", 'what', 're', 'as', \"didn't\", 'didn', 'mightn', 'does', \"you'll\", 'while', 'out', 'is', 'with', 'be', 'you', \"isn't\", 'shan', 'or', \"hadn't\", 'no', 'having', 'll', 'now', 'further', 'below', 'did', 'don', 'was', 'those', 'yourselves', 'after', 'him', 'how', 'both', 'its', 'he', 'where', 'whom', 'himself', 'should', 'we', 'between', 'won', 'd', 'in', 'under', 'aren', \"aren't\", \"wouldn't\", 'me', 'nor', 'on', 've', 'ours', \"mightn't\", 'theirs', 'yours', \"you've\", 'his', 'until', 'for', 'than', 'couldn', 'ma', 'are', 'it', 't', 'against', 'they', 'of', 'most', 'only', \"mustn't\", 'ourselves', 'isn', 'your', \"wasn't\", 'she', \"you'd\", 'doesn', \"it's\", 'some', 'do', \"needn't\"}\n"
     ]
    }
   ],
   "source": [
    "print(en_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_text(reviews):\n",
    "    reviews = reviews.lower()\n",
    "    reviews = reviews.replace(\"<br /><br />\",\" \")\n",
    "    t = tokenizer.tokenize(reviews)\n",
    "    useful = [x for x in t if x not in en_stopwords]\n",
    "    stemmed = [ps.stem(x) for x in useful]\n",
    "    stemmed_review = ' '.join(stemmed)   \n",
    "    return stemmed_review\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'love movi sinc 7 saw open day touch beauti strongli recommend see movi watch famili far mpaa rate pg 13 themat element prolong scene disastor nuditi sexual languag'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_clean_text(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multinommial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [\"This was an awesome,good & awesome movie\",\n",
    "     \"Great movie! I liked it a lot\",\n",
    "     \"Happy Ending! awesome acting by the hero\",\n",
    "     \"loved it! truly great\",\n",
    "     \"bad not good upto the mark\",\n",
    "     \"could have better\",\n",
    "     \"Surely a Disappointing movie\"]\n",
    "\n",
    "y = [1,1,1,1,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awesom good awesom movi',\n",
       " 'great movi like lot',\n",
       " 'happi end awesom act hero',\n",
       " 'love truli great',\n",
       " 'bad not good upto mark',\n",
       " 'could better',\n",
       " 'sure disappoint movi']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_reviews = [get_clean_text(r) for r in x ]\n",
    "clean_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 2 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      "  0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 0\n",
      "  0 0 0]\n",
      " [1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1\n",
      "  1 0 0]\n",
      " [0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0\n",
      "  0 1 1]\n",
      " [0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0\n",
      "  0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "vc = cv.fit_transform(clean_reviews).toarray()\n",
    "print(vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB,GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit(vc,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happi happi love act movi', 'movi saw not good']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = [\"I was happy happy and I loved the acting in the movie\",\n",
    "          \"The movie I saw was not good\"]\n",
    "xt_clean = [get_clean_text(x) for x in test_x]\n",
    "xt_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt_vec = cv.transform(xt_clean).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 39)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict(xt_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.score(vc,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07115831, 0.92884169],\n",
       "       [0.80384651, 0.19615349]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict_proba(xt_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb = BernoulliNB(binarize=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.fit(vc,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.predict(xt_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04579296, 0.95420704],\n",
       "       [0.85047341, 0.14952659]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.predict_proba(xt_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
